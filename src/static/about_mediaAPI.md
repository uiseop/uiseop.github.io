---
title: '[미디어 기술 이해] 6단계로 알아보는 라이브 생방송 송출 원리 (정리)'
date: '2023-12-22 00:00:00'
author: 'uiseop'
categories: [media, player]
summary: '최근 ‘라방’ 이라는 단어의 부상과 함께 Live로 쇼핑도 하고, BTS 공연도 생중계로 볼 수 있게 되었죠. 이처럼 다양한 도메인에서 라이브 방송의 활용도는 높아지고 있습니다. 기존에 녹화된 영상을 시청하는 VOD와는 다른 특징을 가진 라이브 방송. 어떤 원리로 송출되는 것일까요? 이와 관련된 글을 읽고 정리해보도록 하겠습니다.'
---

> 원본: [[미디어 기술 이해] 6단계로 알아보는 라이브 생방송 송출 원리](https://medium.com/naver-cloud-platform/%EB%AF%B8%EB%94%94%EC%96%B4-%EA%B8%B0%EC%88%A0-%EC%9D%B4%ED%95%B4-6%EB%8B%A8%EA%B3%84%EB%A1%9C-%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C-%EC%83%9D%EB%B0%A9%EC%86%A1-%EC%86%A1%EC%B6%9C-%EC%9B%90%EB%A6%AC-86a5137a3655)

## Introduction

H.264, AAC 등 미디어 처리에 대해 알아보고자 하는 과정의 첫 시작으로 네이버 기술팀에서 미디움에 작성해놓은 글을 읽고 정리해보도록 하겠습니다.

### 목차

- 미디어 플랫폼 용어 정리
- 영상이 실제 송출되는데 까지의 과정
  - H.264, AAC 등 미디어 처리란 무엇인가?
  - 스트리밍 프로토콜

## 미디어 플랫폼 용어 정리

최근 Netflix나 Youtube, AfreecaTV와 같은 미디어 플랫폼이 대세를 이루고있습니다. 심지어 [유튜브의 월 평균 사용시간은 이미 카카오톡의 3배를 육박](https://www.donga.com/news/Economy/article/all/20231220/122706420/1)했다고 합니다. 이렇듯 미디어 플랫폼 환경이 유명해지고 이에따른 개발자 수요가 증가하는 지금 저도 미디어 플랫폼에 관심이 생겨서 이번 기회에 미디어 플랫폼에 대해 정리해보려고 합니다.

### 헷갈리는 미디어 용어

![뉴스 캡쳐](https://t1.daumcdn.net/thumb/R1280x0.fpng/?fname=http://t1.daumcdn.net/brunch/service/user/8QmL/image/BPRqltUGhs1LcklQQ6cgpw0rFH4.png)
_(너무나도 많아진 용어...)_

이 용어들을 추려보면 다음과 같습니다.

- OTT
- IPTV
- VOD (SVOD, AVOD, TVOD)

이렇게 3가지로 정리될 것 같습니다. 그럼 차래대로 살펴보죠.

### OTT && IPTV

> `OTT(Over The Top)`: 온라인 동영상 제공 사업자
> `IPTV(Internet Protocol TV)`: 인터넷 티비

우선 결론부터 말씀드리면, **IPTV도 OTT의 한 부분입니다.** OTT를 정의는 `인터넷을 통해 영상을 제공하는 시스템`입니다. 여기서 인터넷을 활용하는 부분에서 `IPTV`가 세부 도메인을 선택한것이기 때문에 `OTT의 부분 집합`이라고 하는 것 이죠.

OTT에서 `Top`은 '제일 위'라는 뜻이 아니라 `셋톱박스`를 얘기한다고 합니다. 셋톱박스는 기존에 위성, 케이블을 통해 송신받던 시스템을 이야기 하는데요, `기존의 시스템의 한계를 극복한 시스템이 OTT`라고 할 수 있겠습니다.

> 참고: 기존 시스템(셋톱박스)의 한계는 케이블/광섬유를 통한 유선 채널 통신 방법으로 한정된 채널만을 송신할 수 있음

하지만, IPTV가 OTT와 구분되는 점은 `어떤 인터넷 망을 사용하는가` 입니다.

**OTT**는 <u>서비스 제공 업체가 소유하지 않은 네트워크 망으로도 송신이 가능한 사업자</u>
**IPTV**는 <u>서비스 제공 업체(SKT/KT/U+)가 소유한 네트워크 망으로만 송신이 가능한 사업자</u>입니다.

그래서 넷플릭스 같은 OTT 사업자는 인터넷만 되면 사용이 가능한것이고, 올레 TV와 같은 경우는 KT 인터넷 망을 사용하는 사람만 가입이 가능했던 것이죠.

#### 정리하면,

> - 기술적으로 인터넷 망을 사용하여 콘텐츠를 제공하는 플랫폼을 크게 OTT라고 부릅니다.
> - 타사의 인터넷 망으로도 서비스가 가능하면 OTT, 자사의 인터넷망으로만 서비스가 가능하면 IPTV입니다.

### VOD

> `VOD(Video On Demand)`: 주문형 비디오 - 사용자가 원하는 영상을 원할 때 볼 수 있는 서비스

이는 OTT, IPTV에서 제공하는 서비스입니다. 자체 영상들을 서버에 저장하여 `사용자가 원하는 시점에 볼 수 있도록 제공하는 서비스죠.`

![VOD 모델들](https://img1.daumcdn.net/thumb/R1280x0.fpng/?fname=http://t1.daumcdn.net/brunch/service/user/8QmL/image/vLI6rF5zuquRfYzlHKuoQzzQ56Q.png)

이 VOD는 `수익 모델별`로 다시 세분화 됩니다. VOD 앞에 한 단어씩 붙어 서로 다른 수익모델을 뜻합니다.

`SVOD`는 구독형 VOD
`AVOD`는 광고 기반 VOD
`TVOD`는 편당 결제 VOD를 뜻합니다.

#### 정리하면,

> - VOD(주문형 비디오)는 OTT(인터넷 망으로 콘텐츠를 제공하는 플랫폼)의 서비스이며,
> - 수익모델에 따라 SVOD(구독으로 수익), AVOD(광고로 수익), TVOD(편당 결제로 수익)로 나뉩니다.

이렇게 해서 미디어 플랫폼에서 사용되는 다양한 용어들을 알아봤으니 이제 개발자 관점에서 미디어 플랫폼이 어떤 프로세스를 통해 영상이 제공되는지 알아보죠.

---

## 영상이 실제 송출되는데 까지의 과정

카메라로 촬영되는 영상이 시청자(클라이언트)에게 전달되기까지, 다음과 같은 단계들을 거치게 됩니다.

> 라이브 방송 영상의 전달 단계
>
> 카메라 ▶ Encoder(인코더) ▶ Media Server(+CDN Server) ▶ 동영상 플레이어 ▶ 시청자(Client)

### 카메라 ▶ Encoder(인코더)

우선, 우리가 시청하는 영상은 카메라를 통해 촬영이 되고 촬영된 영상을 데이터화 시켜 저장한 뒤 저장한 데이터를 시청자(클라이언트)에게 전달함으로써 영상을 시청할 수 있게 되는 것 입니다. 그러면 렌즈에 담긴 영상을 데이터화 시켜야 하는데 이 때 사용되는 것이 바로 `인코더`입니다. 이 인코더에서 `인코딩`을 진행해서 영상을 컴퓨터가 이해할 수 있는 데이터로 변환해주죠.

> **Encoding(인코딩)이란?** "컴퓨터를 이용하여 영상, 이미지 또는 소리 데이터를 생성할 때, 원래의 데이터양을 줄이기 위하여 데이터를 `코드화하고 압축`하는 것. 저장하는 방법에 따른 각각 코덱값이 설정되어 있고, 이러한 파일을 재생할 때에는 코드화된 내용을 원래의 정보로 변환하는 디코딩 작업을 한다." — 출처 : [네이버 국어사전](https://ko.dict.naver.com/#/entry/koko/a6b038c160d6442b80579115fb96c9d1)

압축되지 않은 영상은 무지막지하게 `용량이 크기` 때문에 그대로 작업하면 해당 데이터를 다른 저장소로 옮기는 과정에서 `많은 비용`이 발생합니다. 때문에, 우리는 이렇게 큰 영상을 압축하는 과정이 필요한데, 이 과정에서 `코덱`이란것을 활용합니다.

> **Codec(코덱)이란** "음성 또는 영상과 같은 아날로그 신호를 디지털 신호로 변환하는 `Coder`와 그 반대로 변환시켜주는 `deCoder`의 기능을 함께 갖춘 기술로, 음성이나 비디오 데이터를 컴퓨터가 처리할 수 있게 디지털로 바꿔 주고, 그 데이터를 컴퓨터 사용자가 알 수 있게 모니터에 본래대로 재생시켜 주기도 하는 소프트웨어이다." - 출처 : [네이버 국어사전](https://terms.naver.com/entry.naver?docId=1221296&cid=40942&categoryId=32842)

영상에서 사용되는 대표적인 코덱 중 하나가 `H.264`이고, 음성에서 사용되는 대표적인 코덱이 `AAC`입니다.

> **H.264**: 효율적인 압축률을 보여주는 코덱. `손실 압축 방식`이지만 뛰어난 화질을 유지하며, 동영상 크기를 줄여주기 때문에 `고화질 영상의 웹 배포용으로 많이 사용된다.`

> **AAC**: `MPEG-4 Audio`라고도 불리우는 음성 코덱으로, MP3(MPEG-1 Layer3)에 비해 `뛰어난 음질과 높은 압축률`을 보이지만 `인코딩 시간이 오래 걸린다`는 단점을 갖고 있습니다.

때문에 속도가 중요한 서비스의 경우에는 `AAC`보다는 MP3를 사용하는 것이 더 낫겠죠. 이렇듯 `각각의 상황과 목적에 맞는 압축 방식을 이용한 코덱을 사용`하는 것이 중요합니다.

### Encoder ▶ Media Server(+ CDN Server)

이렇게 인코더를 거쳐 디지털 신호로 변화된 영상 데이터를 저장해야합니다. 데이터를 저장하는 곳은 서버가 되겠죠? 영상을 서버로 보낼 때에 최적화된 프로토콜인 `스트리밍 프로토콜`을 사용하게 됩니다.

> **스트리밍**이란, 멀티미디어 파일을 다운로드 하는 동시에 실행하는 방법이나 기술이며 아래는 대표적인 스트리밍 프로토콜이다.

**Encoder**의 경우 주로 `RTMP(Real Time Messaging Protocol)` 프로토콜을 사용합니다. 과거에는 `UDP`기반의 `RTSP(Real Time Streaming Protocol)` 프로토콜을 많이 사용하였으나 최근에는 RTMP 프로토콜이 거의 표준이 되어가고 있습니다.

### Media Server(+ CDN Server) ▶ 동영상 플레이어

서버에서는 안정적인 송출을 위해 인코더를 통해 받은 영상로 서로 다른 화질(Bitrate)의 `여러 개의 영상을 준비`합니다. 인터넷 방송을 시청하는 시청자의 디바이스/네트워크 환경 등등은 매우 다양하기 때문에 어떤 환경에서도 최적의 화질의 영상을 시청할 수 있도록 서버에서는 `Bitrate 변환` 작업을 진행 합니다.

**Bitrate 변환** 작업은 인코더에서 영상의 화질 변환을 위해 인코딩했던 영상을 다시 디코딩 하고, 화질 변환 작업을 한 뒤 다시 인코딩 작업을 하기 때문에 CPU를 굉장히 많이 사용합니다. 이 과정에서 `GPU 가속`을 사용하면 인코딩 부하를 상당량 줄일 수 있습니다.

Player의 경우에는 HLS(HTTP-Live Streaming), MPEG-DASH가 대표적입니다.​ 때문에 Player에서 이해할 수 있도록 영상을 HLS 프로토콜에 맞게 변환해줘야 합니다.

스트리밍이란 `다운로드와 동시에 미디어가 재생되는 기술`이라고 설명 드렸는데, 스트리밍의 효율적인 동작을 위해서는 파일을 작은 단위로 분할해야 합니다.​

이 과정은 대표적인 Player 프로토콜인 HLS, DASH을 통해 알아보도록 하겠습니다.

#### HLS, DASH를 통해 Player 프로토콜 이해하기

✅ 우선 `H.264 + AAC등 포맷의 동영상 파일을 작은 단위로 분할​`합니다.(용량에 따라 2초 ~10초 단위)

✅ 이와 더불어 분할된 `파일의 재생순서가 작성된 manifest 파일`을 생성합니다.

`manifest파일`에는 분할된 동영상 파일을 어떤 `순서`로 `몇 초간 재생`할 것인지에 대한 내용들이 텍스트로 작성되어 있습니다. `HLS`의 경우에는 `.m3u8 파일`이, `Dash`의 경우 `.mpd(xml)`와 같은 manifest 파일이 생성됩니다.이러한 과정을 거쳐 작은 단위로 분할된 미디어 파일은 mp2ts와 mp4로 구성되어 있고 mp2ts의 확장자는 .ts입니다.

✅ 마지막으로 HLS, DASH를 지원하는 브라우저나 Application에서 `Manifest 파일을 읽어서 재생`합니다. Manifest 파일에 작성되어 있는 텍스트를 통해 분할된 동영상 파일을 순차적으로 읽어 들여 재생하게 됩니다. 따라서 첫번째 segment file을 다 불러오게 되면 재생을 시작할 수 있게 되고, 재생이 진행되면서 2번째 및 3번째 segment file을 뒤에서 계속 실행합니다.

만약 동영상을 중간부터 재생한다고 하면 manifest 파일(.m3u8, mpd)에 근거하여 해당 타임에 맞는 `segment file`을 먼저 다운로드를 하게 될 것입니다.

![Player 프로토콜 과정](https://miro.medium.com/v2/resize:fit:640/format:webp/1*a_3qnp9Bga365Ccl8ZpmmA.png)
_(출처 [http://www.ubik-ingenierie.com/blog/video-streaming-cmaf-and-low-latency/](http://www.ubik-ingenierie.com/blog/video-streaming-cmaf-and-low-latency/))_

최근에는 위 그림과 같이 비디오 스트리밍에 있어서 `공통적인 미디어 포맷을 사용하여 복잡성과 Latency를 줄 일수 있는 CMAF의 등장`으로 빠른 속도로 Adaptive Bitrate Stream을 제공하기 위한 표준이 등장하기도 하였습니다.

### 동영상 플레이어 ▶ 시청자(Client)

Player는 서버에서 받아온 데이터를 시청자에게 영상 형태로 디코딩 시켜서 보여주는 역할을 합니다. 미디어 서버에서 최종적으로 만든 `HLS 형식`은 모바일 단말이라면 안드로이드, 아이폰 구분 없이 내장된 플레이어를 통해 문제없이 재생할 수 있습니다. 그리고 `HLS` 가 `Apple에서 만든 방식`인 만큼 맥 OS에서도 재생을 지원합니다.

다만 `Windows PC`에서 HLS를 재생하려면 별도의 `외부 플레이어`가 필요합니다. Chrome이나 Edge 같이 Adaptive Streamig을 가능케 하는 표준 기술인 `MSE(Media Source Extensions)`를 지원하는 최신 브라우저라면 Javascript 로 구현된 플레이어를 사용할 수 있습니다. 대표적으로 hls.js, video.js 등이 있습니다.

### 출처

- [https://brunch.co.kr/@23why/2](https://brunch.co.kr/@23why/2)
- [https://medium.com/naver-cloud-platform/%EB%AF%B8%EB%94%94%EC%96%B4-%EA%B8%B0%EC%88%A0-%EC%9D%B4%ED%95%B4-6%EB%8B%A8%EA%B3%84%EB%A1%9C-%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C-%EC%83%9D%EB%B0%A9%EC%86%A1-%EC%86%A1%EC%B6%9C-%EC%9B%90%EB%A6%AC-86a5137a3655](https://medium.com/naver-cloud-platform/%EB%AF%B8%EB%94%94%EC%96%B4-%EA%B8%B0%EC%88%A0-%EC%9D%B4%ED%95%B4-6%EB%8B%A8%EA%B3%84%EB%A1%9C-%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C-%EC%83%9D%EB%B0%A9%EC%86%A1-%EC%86%A1%EC%B6%9C-%EC%9B%90%EB%A6%AC-86a5137a3655)
